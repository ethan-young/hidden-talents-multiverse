---
output:
  bookdown::pdf_document2:
    latex_engine: xelatex
    toc: false
    number_sections: false
    keep_tex: true
    extra_dependencies: ["booktabs","caption","longtable","float"]
geometry: margin=1in
mainfont: Times
fontsize: 11pt
endnote: no
urlcolor: blue
header-includes:
- \usepackage{siunitx}
- \usepackage[utf8]{inputenc}
- \usepackage[english]{babel}
- \setlength{\parindent}{2em}
- \setlength{\parskip}{0em}
- \linespread{1.5}
- \usepackage{titlesec}
- \titleformat{\section}[block]{\normalsize\bfseries\filcenter}{}{1em}{}
- \titleformat{\subsubsection}[block]{\bfseries\itshape}{}{1em}{}
- \usepackage{indentfirst}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhf{}
- \fancyhead[R]{\thepage}
- \fancyhead[L]{HIDDEN TALENTS IN CONTEXT}
- \renewcommand\headrulewidth{0pt}
- \usepackage{fixltx2e}
- \usepackage{caption}
- \captionsetup[table]{labelfont={bf},labelformat={default}, labelsep={newline}}
- \captionsetup[figure]{labelfont={bf},labelformat={default}, labelsep={period}}
- \usepackage{lineno}
- \linenumbers
bibliography: references.bib
csl: nature.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = F,
  fig.align = "center",
  fig.pos = "!",  
  fig.show = "asis",
  message = FALSE,
  warning = FALSE
)

library(tidyverse)
library(kableExtra)
library(gt)

load("staged-objects.Rdata")
```

# Abstract

\noindent Children developing in harsh conditions often perform poorly on standard cognitive tests. However, the hidden talents approach proposes that performance for some abilities may be enhanced by adversity or improved under ecologically-relevant conditions. We examine ecologically relevant content in cognitive testing. Sampling 618 socioeconomically diverse adolescents, we measured performance on two versions of an attention shifting and working memory updating task---one abstract, the other ecological. Across multiple sources, we measured environmental unpredictability, violence, and poverty, and tested adversity × task version interactions using a preregistered multiverse approach. We did not find adversity × task version interactions for attention shifting, but there were main effects of unpredictability and violence, indicating improved attention shifting irrespective of task version. For working memory updating, violence- and poverty-exposed youth performed worse on the abstract but not the ecological version, equalizing performance among adversity-exposed youth. We found no relation between updating performance and unpredictability.

*Keywords*: hidden talents, working memory updating, attention shifting, adversity, adaptations to stress

\pagebreak

# Hidden talents in context: Can ecologically-relevant stimuli improve cognitive performance among adversity-exposed youth?

Children living in harsh conditions tend to perform poorly on many cognitive tests. For example, children raised in poverty often show difficulties learning in school and score lower on standardized tests[@ursache2016a; @farah2006; @noble2007; @hackman2010]. Harsh and unpredictable environments are thought to cause high levels of chronic stress, which impacts brain regions responsible for memory and learning[@blair2012]. Thus, the general consensus is that exposure to adversity undermines cognitive development and leads to a host of cognitive impairments[@hackman2010]. Although it is clear that harsh environments are harmful to children, there is growing interest in the *hidden talents* *approach*, which proposes that some abilities may be enhanced by adversity, especially those abilities that are ecologically relevant to lived experience. Thus, hidden talents are skills and abilities that help children meet real-world challenges in adverse environments[@ellis2017; @ellis2020; @frankenhuis2013; @frankenhuis2020].

The hidden talents framework assumes that development shapes the skills and abilities of individuals in relation to their environment[@ellis2017; @ellis2020; @frankenhuis2013; @frankenhuis2020]. Accordingly, exposure to adversity should shape skills and abilities well-suited for dealing with the challenges associated with harsh environments. However, because specific dimensions of adversity (violence versus resource-scarcity) may pose unique challenges[@ellis2020; @frankenhuis2020; @mclaughlin2019; @sheridan2014], the hidden talents approach proposes that cognitive skills should match specific dimensions of adversity[@frankenhuis2020]. For instance, physically abused children can detect angry facial expressions quickly and accurately[@gibb2009; @pollak2008; @pollak2009], people living in poverty have shown some evidence of enhanced social perception[@piff2018], and anxiously attached people are good at deception detection[@eindor2014; @shoda2013] (see[@ellis2017; @ellis2020] for reviews).

Although some abilities themselves are more ecologically relevant to specific dimensions of adversity, hidden talents may also emerge under ecologically relevant conditions. For example, previous studies of hidden talents have tested cognition under ecologically relevant *contexts and situations*. In particular, studies have experimentally manipulated the current context to be uncertain and mildly stressful (or not) and measured performance on executive functioning and working memory tasks[@mittal2015; @young2018] (but see[@nweze2021] for similar results without uncertainty). Strikingly, people from unpredictable environments showed improved performance on attention shifting and working memory updating tasks. However, this effect only emerged under conditions of uncertainty. There was no performance improvement under control conditions.

Hidden talents may also emerge when testing *content and stimuli* are ecologically relevant to adversity-exposed individuals. Typical cognitive tests use abstract content that is largely detached from the real world. Such abstract materials may disadvantage youth with limited exposure to formal education. Cultural psychologists and anthropologists have demonstrated this fact across the world. For example, people from low income and non-western cultures tend to perform worse on standard versions of cognitive tests, but this performance gap closes or disappears with more ecologically relevant versions of the same tests[@banerjee2017; @greenfield2014; @ogbu1981; @richardson1991; @schliemann2002]. These findings pose an important question: Can ecologically relevant testing materials improve cognitive performance among adversity-exposed youth?

One way to test this question is to simply replace sterile testing materials with ecologically relevant content. For example, one study tested memory and reasoning among young adults who varied in their exposures to violence[@frankenhuis2020a]. They created two versions of a memory and reasoning task, one neutral (chronological age) and one more ecologically relevant (social dominance). They found that people with more current exposures to violence were equally good, or even better, at memorizing social-dominance relationships compared to people with fewer exposures. Notably, such violence exposures were associated with worse memory for neutral (age) relationships. There were no associations revealed between violence exposures and reasoning performance. Overall, this study suggests that ecologically relevant testing materials may level the playing field for adversity-exposed youth[@ellis2020; @frankenhuis2020; @rifkin-graboi2021; @vantassel-baska2018]. In addition, although executive functions and working memory are related to many educational outcomes, it is unclear how schools and teachers might leverage skills that specifically depend on inducing uncertainty. That seems impractical, at best, and unethical, at worst.

Here we address this issue by evaluating the role of ecologically relevant content in attention shifting and working memory tasks. To do so, we sampled `r nrow(data2_non_arbitrary)` adolescents from a socioeconomically diverse population. Using interviews, self-reports, and school records, we measured exposure to environmental unpredictability, violence, and poverty. We then tested performance on two widely used tasks: attention shifting and working memory updating. There were two versions of each task. The first used standard abstract stimuli and the second replaced these stimuli with more ecologically relevant ones (see Figure \@ref(fig:figure1)). We then tested the interactive effect of task content and adversity exposure.

We expected adversity-exposed adolescents to benefit more from ecologically relevant stimuli (compared to abstract stimuli) than their counterparts. As such, our primary analyses involved two preregistered confirmatory analyses and one exploratory analysis. Our confirmatory analyses focused on environmental unpredictability and violence exposure because both dimensions have been associated with improved performance under ecologically relevant conditions (contexts and testing materials) and represent specific environmental challenges. Our exploratory analyses focused on exposure to poverty, which is both relevant to hidden talents (e.g., hidden talents could develop in response to specific challenges of poverty) and a general proxy to adversity rather than a specific exposure.

We also evaluated the relative robustness of our models to arbitrary data processing decisions using a multiverse analysis approach[@steegen2016; @simonsohn2020]. Specifically, we systematically and explicitly generated all possible combinations of (arbitrary) data processing decisions and analyzed them simultaneously. We conducted a separate multiverse analysis for each task (attention shifting and working memory updating) and each measure of adversity exposure combination. All multiverse analyses used the same underlying statistical models.


(ref:figure1) Schematic display of the attention shifting and working memory updating tasks: a) abstract attention shifting, b) ecological attention shifting, c) abstract working memory updating, and d) ecological working memory updating.

```{r figure1, fig.cap='(ref:figure1)'}
knitr::include_graphics("figure1.pdf")
```

# Results

## Overview

To test our hypotheses, we performed a set of primary and secondary analyses on attention-shifting and working memory performance. Our primary analyses tested the effects of task version, adversity dimensions, and adversity dimension × task version interactions. Specifically, we tested the main effect of environmental unpredictability (confirmatory), violence exposure (confirmatory), and poverty exposure (exploratory), and the interaction between each adversity dimension with task version (abstract vs. ecological) on attention-shifting and working memory performance. We ran separate analyses for each adversity dimension and outcome combination.

Before conducting analyses, we identified six arbitrary data processing decisions each with two alternatives (see Arbitrary Decisions section). These criteria were 1) including the after-school club sample or not; 2) including participants with minor distractions during testing or not; 3) including participants who missed one trap question or not (those who missed more than 1 were already excluded); 4) including participants receiving special education (participants receiving more \> 60 minutes/day were already excluded) or not; 5) including participants who performed at or below chance levels of accuracy on the attention-shifting task or not (see [attention shifting data cleaning procedure]( https://osf.io/kvt5e/?view_only=92d55bd3b9834468acd3a7cef5c3febd) for more information); and 6) residualizing social desirability scores out of adversity scores or not. Using all possible combinations of arbitrary decisions, we constructed a multiverse of `r length(multi_data_list)` datasets. The minimum and maximum sample sizes were `r map_dbl(multi_data_list, "n") %>% min()` and `r map_dbl(multi_data_list, "n") %>% max()`, respectively.

We ran the same underlying mixed-effects linear regression model. Analyses were conducted using R[@rcoreteam2020] and mixed models were fit using the lme4 package[@bates2015]. Our mixed-effects models included five fixed terms: the main effect of task version (ecological or abstract version, within-subjects), the main effect of childhood adversity (between-subjects), the interaction between task version and adversity exposure, the main effect of age (control variable), and the main effect of test distraction ratings (control variable). Task version was grand mean centered (abstract versions = -1, ecological versions = 1). All childhood adversity measures were standardized before model fitting, and all models included a random intercept for task version nested in participants.

Our models for attention shifting and working memory updating differed in one respect. Our sample included a small subset of siblings (*n* = `r txt6_sib$n`, `r txt6_sib$families` families). All sibling groups were pairs of two (`r txt6_sib$sizes$two` sibling pairs) except for `r english::as.english(txt6_sib$sizes$three)` group of three and `r english::as.english(txt6_sib$sizes$four)` group of four siblings. We computed intraclass correlations (ICCs) for sibling groups for attention-shifting and working memory updating scores. ICCs for attention shifting were essentially zero, but they were non-zero for working memory updating scores (*ICC~standard~* = `r txt6_sib$iccs$abs_update`, *ICC~ecological~* = `r txt6_sib$iccs$eco_update`). Thus, all models analyzing working memory updating included an additional random intercept for siblings. Non-siblings were given the same sibling-group code, so the model could compute an intercept for non-siblings.

To facilitate interpretation of multiverse results, we report median standardized $\beta$s, median 95% confidence intervals, and percent significant for each term in our model (see Table \@ref(tab:table2)). Percent significant refers to the number of analyses (out of `r length(multi_data_list)`) that resulted in a significant effect for a particular term and reflects the relative sensitivity (or robustness) of an effect to arbitrary data processing decisions. For the main effects of adversity and task version × adversity interactions, we used a bootstrapping technique[@simonsohn2020; @orben2019; @orben2019a] to compute overall p-values, which indicate whether a $\beta$ of a term is larger than expected given the null (the median $\beta$ = 0; see Statistical Inferences).

Table \@ref(tab:table1) displays bivariate associations between all composite measures of adversity, including components of each, and descriptive statistics. Our primary interests were the main effect of adversity and the interaction of adversity with task-version. Table \@ref(tab:table2) shows median effect sizes ($\beta$-coefficients), sample sizes, and bootstrapped *p*-values for attention shifting and working memory updating analyses for the main effect of adversity (unpredictability, violence, and poverty) and the interaction term (task version × adversity). Table \@ref(tab:table3) reports median simple effects of task version across high and low levels of adversity and median simple effects of adversity across abstract and ecologically relevant task versions.

```{r table1}
table.01.0 %>% 
  kbl(
    align = "lcccccccccc",  
    booktabs = T,
    escape = F,
    caption = "\\emph{Bivariate correlations and descriptive statistics for all measures of adversity and their subcomponents.}"
  ) %>% 
  add_header_above(c(" ","Unpredictability" = 3, "Violence" = 3, "Poverty" = 4)) %>% 
  kable_styling(latex_options = "scale_down") %>% 
  footnote(
    general       = "Column headers denote adversity constructs and rows indicate components. The upper triangle contain sample sizes for each correlation.",
    general_title = "Note:", 
    symbol        = c("p < .05,","p < .01"),
    symbol_manual = c("*", "**"),
    footnote_as_chunk = T,
    title_format = "italic",
    threeparttable = T
  )
```

Figures \@ref(fig:figure2) and \@ref(fig:figure3) visualize multiverse task version × adversity interaction results for attention shifting and working memory performance, including depictions of performance on abstract and ecological task versions across high ($+$ 1 *SD*) and low ($-$ 1 *SD*) adversity exposure (Figures \@ref(fig:figure2)a and \@ref(fig:figure3)a), p-curves associated with each interaction term (Figures \@ref(fig:figure2)b and \@ref(fig:figure3)b), sorted interaction -coefficients across arbitrary decisions (Figures \@ref(fig:figure2)c and \@ref(fig:figure3)c), sample sizes (Figures \@ref(fig:figure2)d and \@ref(fig:figure3)d), and a specification grid showing the arbitrary data processing decisions associated with each effect (Figures \@ref(fig:figure2)e and \@ref(fig:figure3)e).

We preregistered all primary analyses on the Open Science Framework (OSF; see the [osf project link](https://osf.io/6r95z/?view_only=92d55bd3b9834468acd3a7cef5c3febd), including an [updated primary analysis plan](https://osf.io/4vsnz/?view_only=92d55bd3b9834468acd3a7cef5c3febd), which included more details. We conducted secondary analyses after our primary analyses (see Secondary Analyses below). Before conducting these analyses, we uploaded secondary analysis plans (see the [first secondary analysis plan](https://osf.io/7fu35/?view_only=92d55bd3b9834468acd3a7cef5c3febd) and the [second plan](https://osf.io/wcauf/?view_only=92d55bd3b9834468acd3a7cef5c3febd), explaining the goals and purpose of each secondary analysis. A Red Team Critic[@market] successfully reproduced and verified (see this [red team report](https://osf.io/xv94z/?view_only=92d55bd3b9834468acd3a7cef5c3febd)) all analyses prior to submission.

## Primary Analyses

### Attention Shifting

Across each set of multiverse analyses, there were significant main effects of task version. All median effects sizes for task version were $\beta$s = `r c(mod_terms1$shifting.unp.type_z$median_beta, mod_terms1$shifting.vio.type_z$median_beta, mod_terms1$shifting.ses.type_z$median_beta) %>% mean()` (all *ps* \< .05) for multiverse models testing unpredictability, violence exposure, and poverty exposure, indicating that switch costs were moderately higher for the ecological version compared to the abstract version (see SI Figures 1-3). That is, reaction times on switch trials, compared to repeat trials, were longer when stimuli were ecologically relevant as opposed to abstract. However, there were no effects of age (all median $\beta$s = `r c(mod_terms1$shifting.unp.age$median_beta, mod_terms1$shifting.vio.age$median_beta, mod_terms1$shifting.ses.age$median_beta) %>% mean()`, all *ps* \>.05) or test distraction ratings (all median $\beta$ = `r c(mod_terms1$shifting.unp.test_envr$median_beta, mod_terms1$shifting.vio.test_envr$median_beta, mod_terms1$shifting.ses.test_envr$median_beta) %>% mean()`, all *ps* \> .05) on overall switch costs (see SI Figures 1-3).

(ref:figure2) Visualization of multiverse attention shifting results. Specifically, a) visualizes the multiverse task version × adversity interaction on abstract and ecological task versions across high ($+$ 1 *SD*) and low ($-$ 1 *SD*) adversity exposure, b) plots *p*-curves associated with each interaction term, c) plots sorted interaction $\beta$-coefficients across each arbitrary decision, d) plots the sample sizes for each effect, and e) is a specification grid indicating the data processing decisions associated with each effect.

```{r figure2, fig.height=7.5, fig.width=6.5, fig.cap='(ref:figure2)'}
fig2
```

Overall, there were no significant interaction effects between task version and unpredictability, violence exposure, or poverty exposure (see Table \@ref(tab:table2), Table \@ref(tab:table3), and Figure \@ref(fig:figure2)b). However, analyses produced main effects of unpredictability (median $\beta$ = `r mod_terms2$shifting.unp$median_beta_main`, `r mod_terms2$shifting.unp$p_percent_main %>% str_remove("\\.00")` of *ps* \< .05, overall *p* = `r mod_terms2$shifting.unp$p_overall_main`) and violence exposure (median $\beta$ = `r mod_terms2$shifting.vio$median_beta_main`, `r mod_terms2$shifting.vio$p_percent_main` of *ps* \< .05, overall *p* = `r mod_terms2$shifting.vio$p_overall_main`). (See Table \@ref(tab:table2).) There were no main effects of poverty exposure (median $\beta$ = `r mod_terms2$shifting.ses$median_beta_main`, no *ps* \< .05, overall *p* = `r mod_terms2$shifting.ses$p_overall_main`); see Table \@ref(tab:table2)). That is, exposure to more unpredictability and violence was associated with smaller switch costs, suggesting such exposures are associated with somewhat better shifting performance on average, irrespective of whether stimuli were abstract or ecologically relevant.

```{r table2}
table.02.0 %>% 
  ungroup() %>% 
  mutate(iv = factor(iv, c("Unpredictability","Violence","Poverty"))) %>%
  arrange(dv,iv) %>% 
  select(-dv) %>% 
  mutate(across(.cols = contains("p_percent"), ~ str_replace(.x, "%", "\\\\%"))) %>% 
   kable(
    col.names = c(" ","$\\beta$", "95\\% CI","\\emph{p} (\\%)","\\emph{p}", "$\\beta$", "95\\% CI","\\emph{p} (\\%)","\\emph{p}"),
    booktabs = T,
    escape = F,
    caption = "\\emph{Median standardized effects, 95\\% confidence intervals, percent significant, and bootstrapped p-values for the main effect of adversity and interaction terms for adversity by task version for attention shifting and working memory updating.}"
  ) %>% 
  add_header_above(c(" " = 1, "Main Effect" = 4, "Interaction" = 4)) %>% 
  group_rows(group_label = "Attention Shifting", start_row = 1, end_row = 3) %>% 
  group_rows(group_label = "Working Memory Updating", start_row = 4, end_row = 6) %>% 
  kable_styling(latex_options = "scale_down") %>% 
  footnote(
    general = "The p (%) column reflects the number of analyses that produced p-values < .05 out of all analyses for a given multiverse analyses. The total number of analyses for each measure was 64. Overall p-values were computed using a bootstrapping resampling method and reflect the probability of obtaining an effect size as extreme or more extreme given the median effect is 0.",
    general_title = "Note:", 
    footnote_as_chunk = F,
    title_format = "italic",
    threeparttable = T
  )
```

### Working Memory Updating

Across each set of multiverse analyses, there were again significant main effects of task version. All median effects sizes for task version were $\beta$s = `r c(mod_terms1$updating.unp.type_z$median_beta, mod_terms1$updating.vio.type_z$median_beta, mod_terms1$updating.ses.type_z$median_beta) %>% mean()` (all *ps* \< .05) for models testing unpredictability, violence exposure, and poverty exposure, indicating that updating performance was better when stimuli were ecological relevant compared to abstract, on average (see SI Figures 4-6). There were also consistent main effects of age; median effects were $\beta$ = `r mod_terms1$updating.unp.age$median_beta` (all *ps* \< .05) for unpredictability models, $\beta$ = `r mod_terms1$updating.vio.age$median_beta` (all *ps* \< .05) for violence exposure models, and $\beta$ = `r mod_terms1$updating.ses.age$median_beta` (all *ps* \< .05) for poverty exposure models (see SI Figures 4-6). That is, older adolescents scored higher on working memory updating, on average. Finally, there were some main effects of test environment distraction ratings. Median effects sizes were $\beta$ = `r mod_terms1$updating.unp.test_envr$median_beta` (`r (mod_terms1$updating.unp.test_envr$p_percent *100) %>% round(2)`% of *ps* \< .05) for unpredictability models, $\beta$ = `r mod_terms1$updating.vio.test_envr$median_beta` (`r (mod_terms1$updating.vio.test_envr$p_percent *100) %>% round(2)`% of *ps* \< .05) for violence exposure models, and $\beta$ = `r mod_terms1$updating.ses.test_envr$median_beta` (`r (mod_terms1$updating.ses.test_envr$p_percent *100) %>% round(2)`% of *ps* \< .05) for poverty exposure models, indicating that more test distractions reduced working memory updating performance, on average (see SI Figures 4-6).

Multiverse analyses revealed a main effect of poverty exposure (median $\beta$ = `r mod_terms2$updating.ses$median_beta_main`, all *ps* \< .05, bootstrapped *p* \< .001) but no main effects of unpredictability (median $\beta$ = `r mod_terms2$updating.unp$median_beta_main`, no *ps* \< .05, bootstrapped *p* = `r mod_terms2$updating.unp$p_overall_main`) or violence exposure (median $\beta$ = `r mod_terms2$updating.vio$median_beta_main`, `r mod_terms2$updating.vio$p_percent_main` of *ps* \< .05, bootstrapped *p* = `r mod_terms2$updating.vio$p_overall_main`). Analyses also revealed two significant interactions: task version × violence exposure (median $\beta$ = `r mod_terms2$updating.vio$median_beta_int`, `r mod_terms2$updating.vio$p_percent_int` of *ps* \< .05, bootstrapped *p* = `r mod_terms2$updating.vio$p_overall_int`) and task version × poverty exposure (median $\beta$ = `r mod_terms2$updating.ses$median_beta_int`, `r mod_terms2$updating.ses$p_percent_int` of *ps* \< .05, bootstrapped *p* = `r mod_terms2$updating.ses$p_overall_int`). Adolescents exposed to low levels of violence or poverty tended to perform better on the abstract working memory updating task (violence exposure median *b~abstract~* = `r simple_effects$updating.vio$beta_abs`, `r simple_effects$updating.vio$p_percent_abs` of *ps* \< .05; poverty exposure median *b~abstract~* = `r simple_effects$updating.ses$beta_abs`, all *ps* \< .05), compared to adolescents exposed to high levels of violence and poverty (see Table \@ref(tab:table3) and Figure \@ref(fig:figure3)). However, this performance gap closed on the ecological working memory task (violence exposure median *b~ecological~* = `r simple_effects$updating.vio$beta_eco`, no *ps* \< .05; poverty exposure median *b~ecological~* = `r simple_effects$updating.ses$beta_eco`, `r simple_effects$updating.ses$p_percent_eco` of *ps* \< .05). Put differently, adolescents exposed to high levels of violence or poverty ($+$ 1 *SD*) performed better on the ecologically-relevant version compared to their own performance on the abstract version (median simple *b~high~ ~violence~* = `r simple_effects$updating.vio$beta_high`, all *ps* \< .05; median simple *b~high~ ~poverty~* = `r simple_effects$updating.ses$beta_high`, all *ps* \< .05), whereas adolescents exposed to low violence or poverty ($-$ 1 *SD*) performed similarly across task versions (median simple *b~low~ ~violence~* = `r simple_effects$updating.vio$beta_low`, no *ps* \< .05; median simple *b~low~ ~poverty~* = `r simple_effects$updating.ses$beta_low`, no *ps* \< .05). In this sense, ecologically relevant stimuli appeared to equalize working memory updating performance among adolescents exposed to high levels of violence and poverty (see Table \@ref(tab:table3) and Figure \@ref(fig:figure3)a).

(ref:figure3) Visualization of multiverse working memory updating results. Specifically, a) visualizes the multiverse task version × adversity interaction on abstract and ecological task versions across high ($+$ 1 *SD*) and low ($-$ 1 *SD*) adversity exposure, b) plots *p*-curves associated with each interaction term, c) plots sorted interaction $\beta$-coefficients across each arbitrary decision, d) plots the sample sizes for each effect, and e) is a specification grid indicating the data processing decisions associated with each effect. Proportions of each arbitrary decision with *p*-values < .05 are indicated on the right side of each specification grid. Blank proportions indicate proportions = 0.

```{r figure3, fig.height=7.5, fig.width=6.5, fig.cap='(ref:figure3)'}
fig3
```

## Secondary Analyses

We followed-up our primary analyses with two sets of secondary, exploratory analyses. We uploaded secondary analysis plans to the OSF prior to conducting them (see the [first secondary analysis plan](https://osf.io/7fu35/?view_only=92d55bd3b9834468acd3a7cef5c3febd) and the [second plan](https://osf.io/wcauf/?view_only=92d55bd3b9834468acd3a7cef5c3febd)). These analyses focused on two questions. First, in contrast to prior work[@mittal2015; @young2018], we found limited support for improved working memory updating performance in relation to unpredictability (although we found a main effect of unpredictability on attention shifting). However, prior work measured retrospective perceptions of unpredictability whereas the current combined perceptions with more objective, interview-based measures. Thus, one possibility is that specific components of our composite adversity measures (unpredictability, violence exposure, and poverty exposure) have unique associations with attention shifting and working memory updating performance. To address this, we expanded our multiverse approach to include each component of our predictor variables as additional arbitrary decisions.

The second question focused on the interactive effects of task version × violence exposure and task version × poverty exposure on working memory updating performance. Specifically, primary analyses revealed an equalization effect for both violence and poverty exposures on working memory updating. However, because measures of violence and poverty were not included in the same statistical model, it is unclear whether these interactions are independent. For example, one possibility is that exposures to violence and poverty are independently associated with working memory updating performance. Alternatively, they may overlap, reflecting the same association. To test this question, we ran a focused multiverse analysis with the same controls, main effects of task version, poverty and violence exposure, and two interaction terms: task-version × violence exposure and task-version × poverty in the same model. If violence and poverty exposures interact independently with task version, both interaction terms should remain significant. However, if they represent overlapping effects on working memory updating performance, one or the other may drop out of significance, which would suggest that one or the other adversity dimension is driving the effects of the other.

```{r table3, results='asis'}
table.03.0 %>% 
  ungroup() %>%
  mutate(iv = factor(iv, c("Unpredictability","Violence","Poverty"))) %>%
  arrange(dv,iv) %>% 
  select(-dv) %>% 
  mutate(across(.cols = contains("p_percent"), ~ str_replace(.x, "%", "\\\\%"))) %>% 
   kable(
    col.names = c(" ", "\\emph{b} (abs)", "\\emph{p} (\\%)","\\emph{b} (eco)", "\\emph{p} (\\%)", "\\emph{b} (low)", "\\emph{p} (\\%)","\\emph{b} (high)", "\\emph{p} (\\%)"),
    booktabs = T,
    escape = F,
    caption = "\\emph{Median simple effects (unstandardized) and percent significant for task version and adversity for attention shifting and working memory updating.}"
  ) %>% 
  add_header_above(c(" " = 1, "Task Version" = 4, "Adversity Exposure" = 4)) %>% 
  group_rows(group_label = "Attention Shifting", start_row = 1, end_row = 3) %>% 
  group_rows(group_label = "Working Memory Updating", start_row = 4, end_row = 6) %>% 
  kable_styling(latex_options = "scale_down") %>% 
  footnote(
    general = "Simple effects for Task Version reflect the median effect of adversity in for the abstract version (abs) and ecological version (eco). Simple effects for Adversity reflect the effect of task version when adversity-exposure is low (-1 SD) and high (+1 SD). P-values < .05 out of all analyses for a given multiverse analyses. The total number of analyses for each measure was 64.",
    general_title = "Note:", 
    footnote_as_chunk = T,
    title_format = "italic",
    threeparttable = T
  )
```

### Exploring Components of Adversity Dimensions

We ran an expanded multiverse analysis to explore the effects of each component of our adversity composites on attention shifting and working memory updating performance. Environmental unpredictability contained two components, perceived unpredictability (self-reported) and an interview-based measure tabulating family disruptions, parental figures, and residential moves. Violence exposure contained two self-report components: neighborhood violence and exposure to/involvement in violence. Poverty exposure contained three components: parental education/occupation (interview), perceived resource scarcity (self-report), and school-coded economic disadvantage (fee waivers, free- or reduced-priced lunch, and homelessness).

For this expanded multiverse approach, we retained all original data processing decisions (i.e., original 64 combinations of decisions) and added an adversity component as an additional decision. For unpredictability, we analyzed each unpredictability component and the composite measure (composite analyses are redundant with primary analyses but were retained for comparison purposes), which resulted in 384 analyses (64 original × three versions of unpredictability × two performance measures [attention shifting and working memory]). We applied the same approach to violence exposure (three violence variables, 384 analyses) and poverty exposure (four poverty variables, 512 analyses). The full results of these analyses are reported in the supplement (see SI Table 2).

For attention shifting, consistent with our primary analyses, there were no interactions for any component of adversity and task version (see SI Table 2 and SI Figures 7-9). However, there were a few main effects of adversity. First, primary analyses revealed, under some analytic decisions, a main effect of unpredictability. Upon inspection of each unpredictability component, this effect appeared to be entirely driven by self-reported perceived unpredictability. Specifically, no main effect *p*-values for interview-based unpredictability were \< .05, whereas `r secondary1_medians$shifting.unp.Perceived.iv$p_percent` were for perceived unpredictability (see SI Table 2, SI Table 3, and SI Figure 7). In addition, violence exposure revealed that our primary analyses were driven by neighborhood violence (`r secondary1_medians$shifting.vio.Neighborhood.iv$p_percent` of *ps* \< .05) and not by direct witnessing or involvement in fights (no *ps* \< .05, see SI Table 2, SI Table 3, and SI Figure 8). There were no main effects of poverty exposure components on attention shifting (see SI Table 2, SI Table 3, and SI Figure 9).

For working memory updating, there were no interaction between any unpredictability component (perceived or interview-based) and task-version (see SI Figure 10). However, our expanded analysis with violence exposure revealed that interactions obtained with the composite measure were not driven by neighborhood violence but instead by witnessing or involvement in violence (`r secondary1_medians$updating.vio.Fighting.iv_type_z$p_percent %>% str_remove("\\.00")` of interaction *ps* \< .05, see SI Table 2, SI Table 3, and SI Figure 11). No interactions were significant with the neighborhood violence component of the violence composite. For poverty exposure, interview-based parental occupational prestige and school-reported economic disadvantage showed some interaction effects (parental education/occupational prestige `r secondary1_medians$updating.ses.Parents.iv_type_z$p_percent` of *ps* \<.05; school coded economic disadvantage `r secondary1_medians$updating.ses.School.iv_type_z$p_percent` of *ps* \< .05, see SI Table 2, SI Table 3, and SI Figure 12). Self-reported perceived resource scarcity showed no interaction effects (see SI Table \@ref(tab:table2), SI Table 3, and SI Figure 12).

### Comparing Violence and Poverty Exposure Interactions with Task-Version

Our next secondary analysis was designed to compare the violence exposure × task-version interaction with poverty exposure × task-version interaction on working memory updating performance in the same model. To do so, we ran a multiverse analysis using the original set of `r length(multi_data_list)` data processing decisions. We entered the same controls, main effects of task-version, poverty and violence exposure, and two interaction terms: task-version × violence exposure and task-version × poverty exposure. Analyses revealed a main effect of poverty (`r secondary2_medians$ses_agg_z$p_percent` of *ps* \< .05); consistent with the primary analyses, lower poverty was associated with better updating performance under most analytic decisions. However, there were no main effects of violence exposure (no *ps* \< .05). For interactions, there were no effects of task version × poverty (no *ps* \< .05, see SI Figure 13) and only a small number of significant task version × violence exposure effects (`r secondary2_medians$type_z_vio_agg_z$p_percent` of *ps* \< .05, see SI Figure 13). More specifically, when both interactions were entered into the same model, only task-version × violence exposure remained significant, although only under a small set of analytic decisions.

Violence and poverty exposure interaction patterns were qualitatively similar to those obtained in our primary analyses (see Figure \@ref(fig:figure3)a and SI Figure 13). However, these secondary results suggest that the violence exposure interaction with task-version may be driving our poverty × task version results for working memory updating. One possibility is that the shared variance between poverty and violence exposures (*r* = `r txt5_cor$ses_vio$r`) is responsible for both interaction effects. In other words, although poverty and violence exposure are theoretically distinct, our poverty composite may capture poverty-related violence exposures (e.g., high poverty neighborhoods contain more crime) and therefore interact with task-version. When directly compared, explicit measures of violence exposure remain significant (although only under a small set of analytical decisions), whereas poverty interactions drop out entirely.

# Discussion

We examined how ecologically relevant testing materials affect cognitive performance among adversity-exposed youth. We measured three dimensions of adversity--- environmental unpredictability, violence exposure, and poverty---and tested performance on attention shifting and working memory updating tasks. We administered two versions of each task: one using abstract stimuli and the other using ecologically-relevant stimuli, allowing us to compare performance within- and between-subjects.

Leveraging multiverse analysis[@simonsohn2020; @steegen2016], we tested interactions between dimensions of adversity and task version on attention shifting and working memory updating performance. We did not find interaction effects for attention shifting. However, youth exposed to unpredictability and violence showed smaller switch costs on average, suggesting slightly improved attention shifting performance irrespective of task content. These findings partially diverge from prior work[@mittal2015; @nweze2021]. For example, whereas we found unpredictability was associated with improved attention shifting on average, Mittal and colleagues[@mittal2015] found no difference in performance under neutral conditions. And, although they improved attention shifting for those exposed to high unpredictability under uncertainty, it remains unclear how this effect relates to those obtained in the current study. In addition, Fields and colleages[@fieldsa] found caregiving instability was associated with improved attention shifting, but Nweze and colleagues[@nweze2021] found no association between adversity and attention shifting. However, they tested institutionalized children rather than measuring adversity dimensions[@nweze2021]. In general, we should interpret cautiously. Although we followed field standards for calculating switch costs by computing difference scores, such scores ignore participant-level reaction times. Mixed-modeling approaches can account for both overall reaction times and differences across switch and repeat trials, but require more statistical power to test three-way interactions. Future research should consider more appropriate modeling approaches.

For working memory updating, we found lowered performance among violence- and poverty-exposed youth on the abstract working memory updating task compared to peers with reduced exposures. However, ecological materials produced an equalization effect: the updating performance gap between low and high-adversity exposed youth narrowed on the ecological updating task. Interestingly, updating performance was unrelated to unpredictability. These findings are partially consistent with prior work on adversity exposure and working memory updating performance[@young2018; @nweze2021]. For example, both Young and colleagues[@young2018] and the current study found lowered abstract working memory performance among high adversity-exposed individuals. Although performance with ecological stimuli is not directly comparable to performance under manipulated uncertainty, both studies reduced the updating performance gap under ecologically relevant conditions. However, there are also discrepancies. For example, Young and colleagues[@young2018] found effects with unpredictability and not poverty, whereas the current study found associations with violence and poverty but not unpredictability. Finally, Nweze and colleagues[@nweze2021] found improved working memory performance among institutionalized youth without ecological stimuli or uncertainty manipulations. However, both their adversity and working memory measures were different. Such inconsistencies could be attributed to differences in sampling (adults vs. adolescents), the sampled range of adversity exposure (restricted vs. broad), or methods/design (within- vs. between-subjects design; lab vs. community/school settings). Future research should address these inconsistencies.

Our first set of secondary analyses focused on the components of our adversity composites. For attention shifting performance, the main effect of our unpredictability composite appeared to be driven by self-reported perceived unpredictability and not by the interview-based measure which captured changes in youths' living situations. Likewise, the main effect of violence exposure appeared to be driven by neighborhood violence and not involvement or witnessing fights. For working memory updating, interaction effects involving violence exposure were driven by involvement or witnessing fights but not perceptions of neighborhood violence. All components of poverty exposure measures, except self-reported perceptions of resource scarcity, showed interactive effects with task version on working memory updating. Our second set of secondary analyses compared violence to poverty exposure in the same model. Findings suggest, at least when directly comparing interaction terms, violence exposure × task version predicted the working memory updating equalization effect whereas the poverty × task version interaction did not. Although interesting, all secondary analyses are exploratory, and should be interpreted with caution. Nonetheless, these analyses highlight the need to measure multiple dimensions of adversity, compare them, and consider each measure's report format and source.

Taken together, our equalization patterns of results are striking compared to the backdrop of developmental science, which almost exclusively reports lowered cognitive performance in people exposed to harsh rearing conditions. We also document lowered performance among adversity-exposed youth, but this effect was specific to tests with abstract stimuli, at least for working memory updating. When testing materials have more ecological relevance, adversity-exposed youth perform about as well as youth from affluent backgrounds. These effects have both practical and theoretical implications. Practically, these effects support the idea that ecologically relevant testing materials may "even the playing field" for adversity-exposed youth. That is, pending replication and extension, our data suggest leveraging ecologically relevant materials in education may hold promise for closing achievement gaps[@ellis2017; @ellis2020; @frankenhuis2020]. However, our data also suggest the effect of ecological content may be specific to particular abilities---ecological content actually *lowered* attention shifting performance for everyone compared to abstract content. This negative effect is consistent with other studies reporting lowered performance on tests with ecologically relevant content[@frankenhuis2020; @muskens2019; @duquennois].

Theoretically, our findings support the notion that hidden talents may emerge when using ecologically relevant testing materials, but they also raise questions. In particular, why should ecologically relevant stimuli equalize working memory updating performance for adversity-exposed youth compared to youth with reduced exposures? There are at least three possibilities. First, both impairment and enhancement processes could operate in parallel. While abstract working memory updating performance is impaired, ecological working memory updating performance is enhanced. However, this explanation is difficult to reconcile unless performance on tests with different content rely on or recruit different cognitive processes. If this is true, those mechanisms that process abstract content may be impaired but those that process ecological content are intact or enhanced. Second, there may not be impaired or enhanced processes at all. Instead, ecologically relevant stimuli may activate intact, but normally dormant or underrecruited, working memory updating processes. Thus, when tested under abstract testing conditions, cognitive processes operate at a lower level (remain inactive) but operate normally with ecological testing materials. This makes sense if adversity limits energy and/or cognitive resources. Under such constraints, it may be adaptive to activate expensive cognitive processes only when necessary. Third, ecological testing materials may remove barriers, such as testing anxiety, that disadvantage adversity-exposed youth. Unlike the selective activation of cognitive resources, the additional stressors of testing are removed, allowing cognitive mechanisms to function normally. However, this explanation is difficult to reconcile with experimental work[@mittal2015; @young2018], which finds that mild stress/uncertainty improves performance. Future research should use research designs that can disentangle these explanations.

Our study has several strengths and limitations. First, we leveraged a within-person design, which illuminated the effects of ecological testing materials in the same person. However, the correspondence between each version of our tests was modest for working memory updating (*r* = `r txt5_cor$updating$r`) and low for attention shifting (*r* = `r txt5_cor$shifting$r`). Although the task structure was the same, it is unclear to what extent the ecological tests measured the same construct, especially for attention shifting. Second, although we found some effects of ecological testing materials, we measured previously documented hidden talents. To explore generalizability of ecological content across abilities, future research may create ecological versions of tests known to disadvantage adversity-exposed youth, such as inhibition[@young2018] or working memory retrieval[@young2018], and compare performance to abstract versions. Third, although we used interviews and self-report methods, all of our childhood adversity measures were cross-sectional and some were retrospective. These measurement limitations may be partially offset because our sample was still living in their developmental environment. However, this does not replace the need for prospective, longitudinal measures and cannot eliminate all biases associated with retrospective reporting[@reuben2016]. Thus, it remains unclear to what extent the current environment, rather than the developmental environment, is driving our findings.

Until recently, developmental science has almost exclusively reported lowered cognitive performance in people from harsh conditions. The hidden talents framework has challenged this notion and inspired researchers to document the strengths and abilities of people from adversity. Though much is yet to be done, our data have exciting practical implications, such as developing ecologically relevant materials for education, that might even the playing field for adversity-exposed youth. Theoretically, our data help to refine the hidden talents framework and illuminate future research questions surrounding the unique skills and abilities of people living in harsh conditions.

# Method

## Participants

The current study collected data from `r txt1_sam$raw$n$total` adolescents (*M~age~* = `r txt1_sam$raw$age$mean`, *SD~age~* = `r txt1_sam$raw$age$sd`) from two sources across Salt Lake City, Utah. The first was a middle school and the second were 5 after-school clubs. The middle school sample (seventh and eighth graders, *N* = `r txt1_sam$raw$n$wjms`; `r txt1_sam$raw$sex$wjms$females` females) formed `r (txt1_sam$raw$n$wjms/txt1_sam$raw$n$total * 100) %>% round(2)`% of the total sample and is socioeconomically and ethnically diverse. According to school district records, `r (txt1_sam$raw$free_lunch$wjms/txt1_sam$raw$n$wjms * 100) %>% round(2)`% of students were receiving economic assistance based on family income and/or homelessness (i.e., free or reduced-price lunch or fee waivers). The clubs (*N* = `r txt1_sam$raw$n$bgc`; `r txt1_sam$raw$sex$bgc$female` females) contained a wider age range (*M~age~*= `r txt1_sam$raw$age$bgc$mean`, *SD~age~* = `r txt1_sam$raw$age$bgc$sd`). `r (txt1_sam$raw$free_lunch$bgc/txt1_sam$raw$n$bgc * 100) %>% round(2)`% were receiving free or reduced-price lunch and were also ethnically diverse.

We aggregated data from both sources and applied a set of five exclusion criteria. We applied these criteria before inspecting or testing any relations between predictors and outcomes. Specifically, we excluded participants: 1) with incomplete cognitive task data, 2) with apparent cognitive impairments (e.g., head injuries, disabilities, drug use), 3) who missed two or more trap questions, 4) exposed to extreme distractions during the assessment, and 5) who received more than 60 minutes per day of special education services. After exclusions, the final sample contained `r txt1_sam$non_arb$n$total` adolescents (*M~age~* = `r txt1_sam$non_arb$age$mean`, *SD~age~* = `r txt1_sam$non_arb$age$sd`; `r txt1_sam$non_arb$sex$females` females; `r (txt1_sam$non_arb$n$wjms/txt1_sam$non_arb$n$total * 100) %>% round(2)`% from the middle school).

## Procedure

Data collection involved six parts: consent/assent, demographics form, cognitive testing, structured interview, questionnaire, and a debriefing. Consent was obtained from the primary parent or guardian before assessments and assent was obtained from the participant at the beginning of the session. On the demographics form, participants indicated if they were left-handed, their birthdate, and their racial and ethnic background.

Cognitive testing included abstract (i.e., standard) and ecological versions of an attention-shifting and working memory updating task. Task order (shifting versus updating) and version (abstract versus ecological) were counterbalanced across participants. Some participants started with the attention shifting and then moved to the updating tasks. For those starting with the shifting (or updating) tasks, some started with the abstract version and then completed the ecological version (and vice versa). Regardless of which task was first, participants always completed both versions of one task before moving to the other task.

The interview contained two parts. The first part was about participants' home and family life, such as their family composition, the number of adults in the household, and occupation and education information about caregivers. Participants also reported on the number of romantic partners their caregivers had and if these partners lived with the participant. The second part was about residential mobility. Participants listed all the homes they lived in from birth to age 13. For each home, they reported at which ages they lived in the home. If they moved, they also reported any changes in their family structure (loss or gain of adults in the home), social network (e.g., a new school), and/or town or city.

The questionnaire contained measures focused on the childhood environment. The measures included perceived unpredictability in the home, exposure to neighborhood violence, access to material resources, direct exposure to violence and fighting, and a child version of socially desirable responding.

Procedures across the middle school and after-school clubs were the same, with a few minor differences. First, participants in the clubs completed the tasks before the interview, but the opposite occurred in the middle school. The second was that, in the middle school, the questionnaire was completed in a separate session. Whereas the tasks and interview were completed in a small room, alone with the interviewer, the questionnaire was completed approximately two weeks later in a mass testing context (large computer room). This was done because the middle school was on a strict class schedule, which limited the length of individual sessions. In the clubs, sessions were conducted in the summer during flexible hours.

## Measures

### Attention Shifting

We measured attention shifting with two versions of the color--shape task[@mittal2015; @miyake2012; @friedman2008], which involves categorizing stimuli according to one of two rules (see below). On each trial, the rule is displayed on the top of the screen. Using arrow keys, participants categorized the stimulus as quickly and accurately as possible. Response options appeared at the bottom of the screen (see Figure \@ref(fig:figure1)).

On the abstract (standard) attention-shifting task, participants categorized colored (blue or yellow) shapes (squares or triangles) according to the 'color' or 'shape' rule (see Figure \@ref(fig:figure1)a). For example, if a blue triangle appeared on the screen and the rule was "color", participants categorized the blue triangle as blue. However, if the rule was "shape", participants instead categorized the blue triangle as a triangle.

The ecological attention-shifting task replaced shapes and colors with faces (see Figure \@ref(fig:figure1)b). Faces were either male or female (gender), and were happy or angry (emotion). If a happy female face appeared on screen and the rule was 'gender', for example, participants categorized the face as female. If the rule was 'emotion', participants instead categorized the face as happy. The stimuli for the ecological attention-shifting task were selected from the NimStim library[@tottenham2009]. The same female and male models were used for happy and angry expressions.

For both versions, there were two types of trials: repeat and switch. Repeat trials use the same rule as the previous trial. If the current and previous rule is 'color', for instance, the current trial is a repeat trial. Switch trials are trials where the rule changes from the previous trial. If the current rule is 'color' but the previous was 'shape' (or vice versa), the current trial is a switch trial.

Accuracy on attention-shifting tasks is normally high, and was in the current sample for both versions (*M~standard~* = `r (txt2_dvs$abs_shifting_correct$mean/32 * 100) %>% round(2)`%, *SD~standard~* = `r (txt2_dvs$abs_shifting_correct$sd/32 * 100) %>% round(2)`%; *M~ecological~* = `r (txt2_dvs$eco_shifting_correct$mean/32 * 100) %>% round(2)`%, *SD~ecological~* = `r (txt2_dvs$eco_shifting_correct$sd/32 * 100) %>% round(2)`%).Thus, instead of accuracy, attention-shifting ability is measured by comparing reaction times on repeat trials to switch trials. Reaction times on repeat trials are normally faster than switch trials; average repeat trial reaction times on the abstract and ecological versions were `r txt2_dvs$abs_shifting_re_rt$mean` *ms* (*SD* = `r txt2_dvs$abs_shifting_re_rt$sd` *ms*) and `r txt2_dvs$eco_shifting_re_rt$mean` *ms* (*SD* = `r txt2_dvs$eco_shifting_re_rt$sd` *ms*), respectively. On switch trials, average reaction times were `r txt2_dvs$abs_shifting_sw_rt$mean` *ms* (*SD* = `r txt2_dvs$abs_shifting_sw_rt$sd` *ms*) and `r txt2_dvs$eco_shifting_sw_rt$mean` *ms* (*SD* = `r txt2_dvs$eco_shifting_sw_rt$sd` *ms*) on the standard and ecological versions.

To calculate attention-shifting scores, we first cleaned trial-level data [@friedman2008; @miyake2000]. We removed fast and slow reaction times and removed trials after incorrect responses (see [attention shifting data cleaning procedure]( https://osf.io/kvt5e/?view_only=92d55bd3b9834468acd3a7cef5c3febd) for details). We then subtracted the average reaction time on valid switch trials from the average reaction time on valid repeat trials to calculate switch cost scores. The switch cost measures the relative delay in reaction time caused by switching between categorization rules. Average switch costs on the standard and ecological versions were `r txt2_dvs$abs_shifting_sc$mean` *ms* (*SD* = `r txt2_dvs$abs_shifting_sc$sd` *ms*) and `r txt2_dvs$eco_shifting_sc$mean` ms (*SD* = `r txt2_dvs$eco_shifting_sc$sd` ms), respectively (*r* = `r txt5_cor$shifting$r`, *n* = `r txt5_cor$shifting$n`). Higher switch costs mean longer reaction times on switch trials compared to repeat trials. Larger switch costs indicate less efficient attention shifting.

### Working Memory Updating

Working memory updating was measured using two versions of the continuous counters task[@unsworth2015; @unsworth2008; @young2018], in which participants track a sequence of stimuli containing three different objects (see Figure \@ref(fig:figure1)). Participants keep running counts of each object in sequences nine items long. Each object was displayed for one second at a time. At the end of each sequence, participants reported the number of times each object appeared. For each round, there were three possible correct answers, one for each object type.

In the abstract (standard) version, participants kept running counts of squares, circles, and triangles (see Figure \@ref(fig:figure1)c). The participant must keep track of each shape, updating counts as new shapes appeared, and report them at the end of the sequence. The ecological version followed the same format, but participants kept running counts of three different real-world objects (see Figure \@ref(fig:figure1)d): one positive (five-dollar bill), negative (angry face), and neutral (Salt Lake City bus).

Participants completed five rounds of both versions. The maximum score was 15 for each version (five rounds × three possible correct). On the abstract and ecological versions, participants averaged `r txt2_dvs$abs_updating$mean * 15` (*SD* = `r txt2_dvs$abs_updating$sd * 15`) and `r txt2_dvs$eco_updating$mean * 15` (*SD* = `r txt2_dvs$eco_updating$sd * 15`), respectively (*r* = `r txt5_cor$updating$r`). Higher scores indicate better working memory updating performance.

### Environmental Unpredictability

Our measure of environmental unpredictability integrated information from the interview and questionnaire. The interview contained three variables of interest. The first measured the level of exposure to living in a biologically non-intact family from birth to age 13. Interviewers asked participants about their family composition and the adults that lived with them in the home. If a participant's family composition changed, for example, because of a divorce, interviewers recorded the ages when participants experienced the change and for how long it persisted. A family was considered non-intact if the participant did not live with both biological parents during any period from birth to age 13. Based on the earliest age of disruption, we indexed the onset of exposure to a non-intact family by creating a four-level variable from 0 to 3. A 0 indicated the participant lived in an intact family (lived with both biological parents) from birth until age 13 (*n* = `r (data2_non_arbitrary$unp_interview_disrupted == 0) %>% sum(na.rm=T)`); a 1 indicated that a disruption occurred after the age of 5 (*n* = `r (data2_non_arbitrary$unp_interview_disrupted == 1) %>% sum(na.rm=T)`); a 2 indicated that a disruption occurred before age 5 (*n* = `r (data2_non_arbitrary$unp_interview_disrupted == 2) %>% sum(na.rm=T)`); and a 3 indicated the participant was born into a non-intact family (*n* = `r (data2_non_arbitrary$unp_interview_disrupted == 3) %>% sum(na.rm=T)`). `r is.na(data2_non_arbitrary$unp_interview_disrupted) %>% sum(na.rm=T)`. `r is.na(data2_non_arbitrary$unp_interview_disrupted) %>% sum(na.rm=T) %>% english::as.english() %>% str_to_title()` participants had missing information.

The second interview variable tabulated the number of different parental figures (defined as spouses or boyfriends/girlfriends of the participant's mother and father) who lived in the same home with the participant. Trained interviewers tabulated the total number of co-residing parental figures, excluding the participant's biological mother and father (*M* = `r txt3_ivs$unp_interview_figures$mean`, *SD* = `r txt3_ivs$unp_interview_figures$sd`).

The third interview variable focused on residential changes from birth to age 13 (reported retrospectively). Specifically, interviewers probed participants about the number of different homes they lived in and, in particular, whether moving to a new home involved living with new or different adults. On average, participants experienced `r txt3_ivs$unp_interview_moves$mean` (*SD* = `r txt3_ivs$unp_interview_moves$sd`) that involved changes in residential adults.

The questionnaire included a measure of perceived childhood unpredictability[@mittal2015; @young2018; @szepsenwol2015]. Participants responded to six items that assessed exposure to unpredictability up to age 13: 1) "Things were pretty calm and stable in my house" (reversed); 2) "People moved in and out of my house a lot"; 3) "I had a hard time knowing what my parent(s) or other people in my house were going to say or do from day-to-day"; 4) "My parent(s) argued or fought a lot with each other or with other people"; 5) "My parent(s) changed jobs a lot"; 6) "My parental situation changed a lot (for example, divorce or separation of parents, parents starting new romantic relationships, parents leaving the home)". Participants rated each item on a scale from 1 (never true) to 5 (very often true). Responses to these items were averaged to create a self-reported perceived childhood unpredictability measure (*M* = `r txt3_ivs$unp_perceived$mean`, *SD* = `r txt3_ivs$unp_perceived$sd`, $\alpha$ = `r txt4_rel$unp`). Higher scores indicated more perceived exposure to unpredictable environments.

To create a composite measure of unpredictability, we aggregated across the interview and questionnaire. First, we created an interview-based measure of unpredictability using family disruptions, exposure to different parental figures, and residential moves involving new adults living in the home. We standardized these interview measures and then averaged them together ($\alpha$ = `r txt4_rel$unp_int`). We then aggregated this interview measure with self-reported perceived unpredictability from the questionnaire, standardizing each before averaging (*r* = `r txt5_cor$unp$r`). Higher scores indicated more exposure to unpredictability.

### Violence Exposure.

We measured violence exposure using the Neighborhood Violence Scale (NVS)[@frankenhuis2020a; @frankenhuis2018] and two items about witnessing and involvement in physical fights. The NVS contains 7 items rated on a scale from 1 (never true) to 5 (very often true): 1) "I grew up in a safe neighborhood"; 2) "Crime was common in the neighborhood where I grew up"; 3) "In the neighborhood where I grew up, people had plenty of money" (reversed); 4) "In the neighborhood where I grew up, physical fights were common"; 5) "In the neighborhood where I grew up, shootings or stabbings occurred"; 6) "In the neighborhood where I grew up, most people felt unsafe walking alone after dark"; 7) "Where I grew up, it was important to be able to defend yourself against physical harm". The physical fighting items asked about witnessing fights: "Based on your experiences at school and in your neighborhood, how many times did you see or hear someone being beaten up in real life?"; and involvement in fights: "How many times were you in a physical fight at school or in your neighborhood?". Both items were rated on a scale from 1 (0 times) to 8 (12 or more times).

Responses on the NVS were averaged to create a composite measure (*M* = `r txt3_ivs$vio_neighborhood$mean`, *SD* = `r txt3_ivs$vio_neighborhood$sd`, $\alpha$ = `r txt4_rel$vio`). Likewise, the two fighting were averaged together (*M* = `r txt3_ivs$vio_fighting$mean`, *SD* = `r txt3_ivs$vio_fighting$sd`). To create a violence exposure composite, the NVS composite and fighting composite were standardized and then averaged (*r* = `r txt5_cor$vio$r`). Higher scores indicated more exposure to violence.

### Poverty Exposure

We assessed each participant's poverty exposure using three information sources: interview-assessed parent education and occupational prestige, school or club-provided economic information, and perceived resource scarcity.

During the interview, participants reported their parents' education and primary occupation. For parental education level, participants reported whether their mother and father graduated high school, went to college, and if they obtained a bachelor's degree or higher. Responses to each question were coded as 0 = 'no' and 1 = 'yes'. These items were summed to create a four-level variable for each parent where 0 = did not graduate high school, 1 = graduated high school but did not attend any college, 2 = graduated high school and completed some college, and 3 = went to college and obtained a bachelor's degree or higher. Mother and father education were averaged to create a parental education score (*M* = `r txt3_ivs$ses_interview_edu$mean`, *SD* = `r txt3_ivs$ses_interview_edu$sd`).

Participants also reported their parents' occupation. Participants described, in general terms, their mother's and father's jobs and the kind of work involved. Trained coders cross-referenced these descriptions with 2010 census job codes[@hout2018]. We calculated mother and father occupational prestige by matching census codes with prestige ratings from an established occupational prestige rating dataset[@hout2016]. Prestige codes ranged from 0-100, with higher scores indicating higher occupational prestige for a particular job code. Mother and father prestige codes were averaged to create a parent occupational prestige score (*M* = `r txt3_ivs$ses_interview_occup$mean`, *SD* = `r txt3_ivs$ses_interview_occup$sd`).

We also obtained school or club-provided economic information. The middle school provided four information sources: 1) whether or not students were receiving free lunch (*n* = `r (data2_non_arbitrary$ses_school_wjms_frl == 1) %>% sum(na.rm=T)`); 2) whether or not they were receiving reduced-price lunch (*n* = `r (data2_non_arbitrary$ses_school_wjms_rel == 1) %>% sum(na.rm=T)`); 3) whether they were receiving fee waivers (*n* = `r (data2_non_arbitrary$ses_school_wjms_fee == 1) %>% sum(na.rm=T)`); and 4) if they were experiencing homelessness (*n* = `r (data2_non_arbitrary$ses_school_wjms_hom == 1) %>% sum(na.rm=T)`). These information sources were compiled to create a binary economic disadvantage variable. A participant was economically disadvantaged if they were receiving any benefits or experiencing homelessness (*n* = `r txt1_sam$non_arb$free_lunch$wjms`). In the afterschool clubs, free or reduced-price lunch status was provided by self-report, staff, and club enrollment forms and cross-referenced to determine economic disadvantage in the clubs (*n* = `r txt1_sam$non_arb$free_lunch$bgc`). Overall, `r (data2_non_arbitrary$ses_school_freelunch == 1) %>% sum(na.rm=T)` participants were receiving economic assistance, `r (data2_non_arbitrary$ses_school_freelunch == 0) %>% sum(na.rm=T)` were not, and `r sum(is.na(data2_non_arbitrary$ses_school_freelunch))` had missing economic information.

Participants also reported their perceived level of resource scarcity. They rated seven items from 1 (never true) to 5 (very often true): 1) "Your family had enough money to afford the kind of home you all needed"; "Your family had enough money to afford the kind of clothing you all needed"; 3) "Your family had enough money to afford the kind of food that you all needed"; 4) "Your family had enough money to afford the kind of medical care that you all needed"; 5) "I felt well-off (rich, wealthy) compared to other kids in my school"; 6) "I felt well-off (rich, wealthy) compared to other kids in my neighborhood"; and 7) "Your family struggled to make ends meet (get by financially)". The first six items were reversed, and all items were averaged to create a perceived resource scarcity measure (*M* = `r txt3_ivs$ses_perceived$mean`, *SD* = `r txt3_ivs$ses_perceived$sd`, $\alpha$ = `r txt4_rel$ses`). Higher scores indicated more perceived resource scarcity.

To create a poverty exposure composite, we combined parent education and occupational prestige (reversed), school/club reported economic disadvantage, and perceived resource scarcity. First, we standardized and averaged parent education and occupation (*r* = `r txt5_cor$edu_int$r`). Then, we recoded school-provided economic codes to be equal to half of a standard deviation above and below the mean (in terms of z-scores). Specifically, those receiving free or reduced-price lunch were coded as .5, and those who were not were coded as -.5. To create a final composite, we averaged parent education/occupation (standardized), perceived resource scarcity (standardized), and the recoded school/club economic disadvantage. Higher values indicated more exposure to poverty.

### Control Variables

We included two control variables: age and interviewer-rated distractions during testing. We included these because older adolescents tend to score higher on cognitive tests than younger adolescents[@best2010; @best2011; @huizinga2006], and disruptions during the tasks could negatively impact performance. Interviewers completed quantitative ratings of the testing environment including 1) the level of noise; 2) the level of chaos; 3) how often there were interruptions; and 4) how often the participant appeared distracted. Interviewers rated each item on a scale from 1 (not at all) to 7 (much more than average). Items were averaged to create a composite (*M* = `r txt3_ivs$test_envr$mean`, *SD* = `r txt3_ivs$test_envr$sd`), where higher scores indicate more distractions.

We also included the Child Social Desirability (CSD) scale[@miller2014]. The measure includes 14 items such as "Have you ever broken a rule?" and "Do you sometimes feel angry when you don't get your way?". Participants indicated 1 (yes) or 0 (no) for each item. More socially desirable responses were scored as 1. Items were then summed to create a social desirability index (*M* = `r txt3_ivs$csd$mean`, *SD* = `r txt3_ivs$csd$sd` , $\alpha$ = `r txt4_rel$csd`).

## Multiverse Setup

We used a multiverse analysis approach for all analyses[@steegen2016; @simonsohn2020; @orben2019; @orben2019a]. Researchers face many data processing decisions. These decisions fall into two classes: arbitrary and non-arbitrary decisions. Non-arbitrary decisions have clear theoretical, statistical, or practical justifications and are superior to alternatives. Arbitrary decisions are those that have (sometimes many) equally defensible alternatives. For example, excluding outliers at +/- 2.5 or 3 standard deviations above (or below) the sample mean could be equally defensible. Instead of cherry-picking one or getting pigeonholed with the other, multiverse analysis allows researchers to explicitly generate all possible combinations of (arbitrary) data processing decisions and analyze them together. In turn, researchers can systematically evaluate the robustness or sensitivity of their analysis across all possible data processing decisions.

### Arbitrary Decisions.

We identified six arbitrary data processing decisions. First, we conducted analyses with and without the after-school club sample. We did this because our procedure was slightly different across the two samples and the testing environment was more disruptive in the clubs compared with the middle school. Second, we conducted analyses with and without participants with minor distractions during testing. Third, we analyzed the data with and without participants who missed one trap question (those who missed more than 1 were already excluded). Fourth, we analyzed data with and without participants having any amount of special education (participants receiving more \> 60 minutes were already excluded). Fifth, we analyzed data with and without participants who performed at or below chance levels of accuracy on the attention-shifting task (see [attention shifting data cleaning procedure]( https://osf.io/kvt5e/?view_only=92d55bd3b9834468acd3a7cef5c3febd) for more information).

Our last arbitrary data processing decision pertained to socially desirable responses. It is well-known that some youth tend to describe themselves in socially desirable ways. This raises concerns about the validity of self-reported childhood adversity measures: youth scoring higher on social desirability might underreport or underrate their exposures to negative experiences. Indeed, scores on the CSD were correlated with exposures to unpredictability (*r* = `r txt5_cor$csd_unp$r`) and violence (*r* = `r txt5_cor$csd_vio$r`), though not with poverty. One way to handle this issue is to statistically remove overlapping variance between social desirability and each predictor, using the leftover variance (e.g., the residual variance in childhood adversity exposures not associated with social desirability) as a predictor. Because it is unclear how social desirability might affect the interpretation of our models, we analyzed our data with residualized and non-residualized predictors.

### Statistical Inferences.

Multiverse analysis produces a distribution of effect sizes and test statistics across all combinations of analytic decisions (see Figures \@ref(fig:figure2) and 3). However, although these distributions provide rich descriptive information, they do not lend themselves to straightforward null-hypothesis tests. This is because each individual analysis in a multiverse is not independent. To address this, we used a bootstrapping technique designed for multiverse analysis[@simonsohn2020; @orben2019; @orben2019a]. This technique makes it possible to know if a multiverse analysis produced a median effect size larger than expected, given the null hypothesis (the median effect is 0).

For the current study, we calculated overall p-values for the main effect of adversity and the interaction effects (task version × adversity) of our primary analyses. To do so, we created 'null' attention-shifting and working memory updating scores[@simonsohn2020]. That is, we created outcome scores with the influence of the effect of interest (i.e., main effect or interaction) removed. More specifically, we multiplied the coefficient of interest (regression coefficient of the main effect of adversity or interaction effect) by each participant's raw predictor score (either adversity scores or task version × adversity scores) and subtracted the result from each participant's attention-shifting and working memory scores. Next, we randomly sampled participants (with replacement) to create 500 bootstrapped samples. Then, we ran the same multiverse analysis on each bootstrap sample using the null attention-shifting and working memory scores as outcome variables. Upon completion, we compared the median effects for each bootstrapped sample (500 median effect sizes) with our original median effects. To compute overall p-values, we divided the number of effect sizes obtained from the bootstrapped multiverse analyses that were larger than our original median effect sizes by the total number of bootstrapped samples. Importantly, we ran this procedure separately for each measure of adversity (unpredictability, violence exposure, and poverty exposure), outcome (attention shifting and working memory updating), and effect of interest (main effect or interaction effect) combination.

\pagebreak

# References
